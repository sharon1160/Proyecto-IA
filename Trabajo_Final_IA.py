# -*- coding: utf-8 -*-
"""Trabajo_Final_IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zoQakqcG8Wlf6qNVKKFDM-lI7x8hzFpm
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn import model_selection
import matplotlib.pyplot as plt

import numpy as np
import pandas as pd

# DecisionTreeClassifier (Arbol de decisiones)
# LogisticRegression (Regresión Logística)
# SVC (SVM)

# SGDClassifier (Descenso de Gradiente Estocástico)
# GaussianNB (Gaussian Naive Bayes)

# Creamos una lista de los nombres de la base de datos para luego mostrarlos en los resultados
db_names = ['Balance Database',
            'Car Database',
            'Dermatology Database',
            'Ecoli Database',
            'Hepatitis Database',
            'Mammographic Database',
            'Nursery Database',
            'Saheart Database',
            'Wine Database',
            'Zoo Database']

###### Cargamos las 10 bases de datos ######

# Creamos un array de base de datos
dataBase_list = []

# BALANCE
df = pd.read_csv('balance.csv').astype('category').apply(lambda x: x.cat.codes) # ver si es necesario esto siempre
dataBase_list.append(df)

# CAR
df = pd.read_csv('car.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# DERMATOLOGY
df = pd.read_csv('dermatology.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# ECOLI
df = pd.read_csv('ecoli.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# HEPATITIS
df = pd.read_csv('hepatitis.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# MAMMOGRAPHIC
df = pd.read_csv('mammographic.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# NURSERY
df = pd.read_csv('nursery.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# SAHEART
df = pd.read_csv('saheart.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# WINE
df = pd.read_csv('wine.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# ZOO
df = pd.read_csv('zoo.csv').astype('category').apply(lambda x: x.cat.codes)
dataBase_list.append(df)

# Creamos una lista de target
target_list = ['Balance_scale','Acceptability','Class','Site','Class','Severity','Class','Chd','Class','Type']

# Creamos una lista de labels
labels_list = []
# Creamos una lista de features
features_list = []

for i in range(len(dataBase_list)):
  target = target_list[i]
  df = dataBase_list[i]

  label = np.array(df[target])
  labels_list.append(label)

  features = np.array(df.drop(target, axis=1))
  features_list.append(features)

  print("################",db_names[i],"################\n")
  # muestra las dimensiones rows x columns (caracteristicas)
  print("Features Shape:",features.shape)
  # muestra las dimensiones para la columna Clase
  print("Label Shape:",label.shape) 
  print()

# prepare models
models = []
models.append(('LR', LogisticRegression(solver='liblinear'))) # Regresion Logistica
models.append(('DTC', DecisionTreeClassifier(criterion='entropy', splitter='random',  max_depth=3, random_state=1))) # Arbol de Decisiones
models.append(('SVM', SVC())) # SVM
models.append(('SGD', SGDClassifier(max_iter=1000, tol=1e-3))) # Descenso de Gradiente Estocástico
models.append(('NB', GaussianNB())) # Gaussian Naive Bayes

# Analiza cada base de datos para cada modelo

results = []
results2 = []

for i in range(len(dataBase_list)):

  # Recorremos cada features y label
  features = features_list[i]
  label = labels_list[i]

  print("################",db_names[i],"################\n")
  print("Algoritmo \tPromedio\tDesviación E.")

  # genera 10 folds
  kfold = model_selection.KFold(n_splits=10) 
  # para medir el accuracy
  scoring = 'accuracy' 

  for name, model in models:
    # realizamos validacion cruza en los 10 folds para cada uno de los modelos especificados
    cv_results = model_selection.cross_val_score(model, features, label, cv=kfold, scoring=scoring) 

    # Hallamos el promedio y desviación estándar para cada resultado
    promedio = cv_results.mean()
    dev_standar = cv_results.std()

    print("%s:\t\t %f\t (%f)" % (name, promedio, dev_standar))
    
    results.append(promedio)
    results2.append(dev_standar)

# Guardamos el promedio de cada modelo para cada base de datos
LR_list = [ results[i] for i in range(0,len(results),5)]
CART_list = [ results[i] for i in range(1,len(results),5)]
SVM_list = [ results[i] for i in range(2,len(results),5)]
SGD_list = [ results[i] for i in range(3,len(results),5)]
NB_list= [ results[i] for i in range(4,len(results),5)]

# Guardamos la desviación estándar de cada modelo para cada base de datos
LR_list2 = [ results2[i] for i in range(0,len(results),5)]
CART_list2 = [ results2[i] for i in range(1,len(results),5)]
SVM_list2 = [ results2[i] for i in range(2,len(results),5)]
SGD_list2 = [ results2[i] for i in range(3,len(results),5)]
NB_list2 = [ results2[i] for i in range(4,len(results),5)]

print(LR_list)
print(CART_list)
print(SVM_list)
print(SGD_list)
print(NB_list)
print()
print(LR_list2)
print(CART_list2)
print(SVM_list2)
print(SGD_list2)
print(NB_list2)

# REGRESION LOGÍSTICA
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, LR_list )
fig.suptitle('Regresión Logística')

# ARBOLES DE DECISIONES
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, CART_list )
fig.suptitle('Árbol de decisiones')

# SVM
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, SVM_list )
fig.suptitle('SVM')

# SGD
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, SGD_list )
fig.suptitle('Descenso de Gradiente Estocástico')

# Bayes
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, NB_list )
fig.suptitle('Gaussian Naive Bayes')

# REGRESION LOGÍSTICA
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, LR_list2 )
fig.suptitle('Regresión Logística')

# ARBOLES DE DECISIONES
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, CART_list2 )
fig.suptitle('Árbol de decisiones')

# SVM
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, SVM_list2 )
fig.suptitle('SVM')

# SGD
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, SGD_list2 )
fig.suptitle('Descenso de Gradiente Estocástico')

# Bayes
fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)
axs.barh(db_names, NB_list2 )
fig.suptitle('Gaussian Naive Bayes')